Chapter 2: Core Concepts of Quality and Safety
2.1 Core Concepts of Quality
2.1.1 Introduction to Quality
Merriam-Webster defines quality as “a high
level of value or excellence.” The Institute of
Medicine has defined quality of care as “the
degree to which health services for individuals
and populations increase the likelihood of
desired health outcomes and are consistent
with current professional knowledge.” As it
relates to diagnostic imaging and image-guided
treatment, quality can be considered to be “the
extent to which the right procedure is done in
the right way, at the right time, and the correct
interpretation is accurately and quickly
communicated to the patient and referring
physician. The goals are to maximize the
likelihood of desired health outcomes and to
satisfy the patient.”
Several important concepts are connected to
these statements.
First, quality has two important dimensions:
excellence and consistency. It is not enough to
provide excellent care; it must be done on a
consistent basis. Lack of consistency is a marker
of poor quality.
Second, performance must be monitored to
ensure consistent quality. It is unlikely for an
organization to achieve consistent excellent
performance in the absence of performance
standards or measurements.
Third, the goals are twofold: 1) maximize the
likelihood of health outcomes desired by the
patient and 2) satisfy the patient. In other
words, optimizing health outcomes and patient
experience are both important goals of
healthcare. Furthermore, while excellence may
be a subjective term, the ultimate arbiter of
“quality” is the patient. Those who wish to
provide quality care must understand and seek
to achieve consistent excellence from the
perspective of the patient—which may differ
from that of the provider.
Fourth, the goal is to consistently achieve
desired health outcomes using methods that are
consistent with current professional
knowledge. Achieving excellent outcomes on a
consistent basis depends on consistency in the
methods, or processes, that are used to achieve
those outcomes. Therefore, a major goal of
quality is that of decreasing unnecessary
variation, both in processes and outcomes. In a
practice with multiple professionals, this
generally requires those professionals to
collaborate in developing and adhering to
practice standards based on the evidence.
2.1.2 Quality as a Discipline
Achieving consistent excellence in processes
and outcomes is challenging in healthcare,
including in radiology. However, healthcare is
by no means the only field in which consistent
excellence is desired. Over the past century,
“quality” has emerged as its own discipline of
study and practice, with a set of broadly
applicable definitions, principles, and tools.
Quality control (QC) refers to measuring and
testing elements of performance to ensure that
standards are met and correcting instances of
poor quality. An example of a QC activity is
when a radiologistreviews and corrects errors
in a radiology report before finalizing it.
Quality assurance (QA) refers to a process for
monitoring and ensuring performance quality
in an organization. This includes QC activities,
but also refers to strategies designed to prevent
instances of poor quality. An example of a QA
activity is the use of standardized report
templates to minimize errors in reporting
accompanied by verification of appropriate use
with audit-based performance metrics.
Quality improvement (QI) refers to activities
designed to improve performance quality in an
organization in a systematic and sustainable
way. This requires a deliberate effort within an
organization to agree on a measurable
performance objective, measure the relevant
performance, understand the causes of poor
performance, develop and implement strategies
to improve performance, and ensure that those
strategies are embedded in the organization
such that performance will not relapse. An
example of QI is a project whereby radiologists
agree to improve consistency in reporting using
standardized radiology report templates,
implement those templates, monitor radiology
reports and make necessary adjustments, and
ensure that consistency is maintained through
feedback and accountability.
QC is generally considered to be the most basic
level of quality-related activities in an
organization. QA is more comprehensive than
QC and is required to maintain consistently
high performance levels in an organization.
However, QA typically is designed to maintain
rather than improve performance, implying
that quality was presumed to be adequate in
the first place. QI, on the other hand, assumes
that quality is not as good as it could be and
employs strategies to successfully improve
quality through a variety of means, including
changes in processes, systems, and even
organizational structure. As organizations’
focus has transitioned in recent decades from
seeking to maintain the status quo to seeking to
constantly improve performance, the field of
quality has transitioned from relying solely on a
QA approach to one of continuous quality
improvement (CQI).
Quality methods and philosophies have
evolved in several other important ways in the
past several decades:
• Rather than being solely the purview of
a “quality department,” quality has
come to be recognized as the
responsibility of everyone in the
organization—especially organizational
leaders.
• The focus has shifted from detecting
and correcting errors that have already
occurred to improving processes and
systems to prevent errors from
happening or from causing harm.
• Frontline staff are increasingly engaged
to help improve processes.
• The value of making errors visible
rather than quietly fixing them without
sharing them with the staff is
increasingly recognized. Exposing
errors allows them to be more easily
detected so they can be corrected and
their causes addressed.
2.1.3 2001 Institute of Medicine Report,
Crossing the Quality Chasm
In 2001, the Institute of Medicine (IOM)
published a report entitled, “Crossing the
Quality Chasm: A New Health System for the
21st Century.” In this report, the IOM
committee members maintained that all
healthcare constituencies, including
policymakers, purchasers, regulators, health
professionals, health- care trustees and
management, and consumers, should commit
to a shared explicit purpose to continually
reduce the burden of illness, injury, and
disability, and improve the health and
functioning of the people of the United States.
The committee asserted that healthcare should
be:
• Safe—avoiding injuries to patients from
the care that is intended to help them.
• Effective—providing services based on
scientific knowledge to all who can
benefit and refraining from providing
services to those not likely to benefit
(avoiding underuse and overuse).
• Patient-centered—providing care that is
respectful of and responsive to
individual patient preferences, needs,
and values and ensuring that patient
values guide all clinical decisions.
• Timely—reducing waits and potentially
harmful delays for both those who
receive and those who give care.
• Efficient—avoiding waste, in particular
waste of equipment, supplies, ideas, and
energy.
• Equitable—providing care that does not
vary in quality because of personal
characteristics.
Since its publication, the IOM “Chasm” report,
which was itself a follow-up to a 2000 IOM
report on medical error, has provided a road
map for individuals and organizations in
healthcare to focus their improvement efforts.

2.1.4 Core Competencies of the ABMS and
ACGME
To encourage active physician participation in
advancing the goals of continuous
improvement, in 1999 the Accreditation Council
for Graduate Medical Education (ACGME) and
the American Board of Medical Specialties
(ABMS), which is composed of subspecialty
boards including the American Board of
Radiology, described six core competencies that
all physicians should attain.
• Practice-based Learning and Improvement:
Show an ability to investigate and
evaluate patient care practices, appraise
and assimilate scientific evidence, and
improve the practice of medicine.
• Patient Care and Procedural Skills: Provide
care that is compassionate, appropriate,
and effective treatment for health
problems and promote health.
• Systems-based Practice: Demonstrate
awareness of and responsibility to the
larger context and systems of
healthcare. Be able to call on system
resources to provide optimal care (e.g.,
coordinating care across sites or serving
as the primary case manager when care
involves multiple specialties,
professions, or sites).
• Medical Knowledge: Demonstrate
knowledge about established and
evolving biomedical, clinical, and
cognitive sciences and their application
in patient care.
• Interpersonal and Communication Skills:
Demonstrate skills that result in
effective information exchange and
teaming with patients, their families,
and professional associates (e.g.,
fostering a therapeutic relationship that
is ethically sound; using effective
listening skills with nonverbal and
verbal communication; and working
both as a team member and, at times, as
a leader).
• Professionalism: Demonstrate a
commitment to carrying out
professional responsibilities, adhering to
ethical principles, and being sensitive to
diverse patient populations.
By establishing this set of competencies, the
ACGME and ABMS assert that the skills
necessary to effectively practice medicine in a
modern complex healthcare environment
extend beyond the traditional domains of
medical knowledge and individual practice. It
is not enough for professionals to gain adequate
knowledge; they must also continuously
improve their knowledge and practice for the
duration of their careers. They must be not only
technically competent, but also compassionate
and ethical. They must practice effectively not
only as individuals, but also as members of
teams, organizations, and systems of care.
Organizations and leaders who are responsible
for certifying competence of practitioners must
demonstrate adequacy of the professional’s
competence in all domains.
2.2 Core Concepts of Safety
2.2.1 2000 Institute of Medicine Report, To Err
is Human
In 1998, the National Academy of Sciences’
Institute of Medicine (IOM) initiated the
Quality of Health Care in America project to
develop a strategy that would result in
improved quality of care in the United States.
To Err is Human: Building a Safer Health
System, published in 2000, was the first in a
series of reports arising from this project. The
report’s findings that between 44,000 and
98,000 in-hospital deaths per year were
attributable to medical errors made national
headlines, including a suggestion that an
epidemic of death from medical errors
exceeded that from motor vehicle accidents,
breast cancer, or AIDS. The report projected
total societal costs of medical errors to be
between $17 billion and $29 billion.
The report defined medical error as the failure
of a planned action to be completed as intended
or the use of a wrong plan to achieve an aim,
with the highest risk for errors occurring in
high-acuity environments such as the intensive
care unit, operating room, and emergency
department. The report identified several
fundamental factors contributing to the errors,
including the following: 1) the decentralized
nature of the healthcare delivery system (or
“nonsystem,” as the report calls it); 2) the
failure of licensing systems to focus on errors;
3) the impediment of the liability system to
identify errors; and 4) the failure of third- party
providers to provide financial incentive to
improve safety.
The report authors emphasized that most errors
are multifactorial; most errors can be attributed
to unsafe systems and processes of care as well
as to human error. Therefore, the only strategy
to decrease medical errors that is likely to be
both successful and sustainable in the long run
is to design safety into systems and processes of
care. Blaming and “rooting out the bad apples,”
the authors contended, is not a viable strategy
to decrease error.
2.2.2 2015 Institute of Medicine Report,
Improving Diagnosis in Health Care
In 2015, the IOM issued what it considered to
be a follow-up report to its 2000 report on
medical error, this time focusing on diagnostic
error. In this report, Improving Diagnosis in
Health Care, the IOM committee defined
diagnostic error as “the failure to establish an
accurate and timely explanation of the patient’s
health problem(s) or (b) communicate that
explanation to the patient.” The definition is
purposely patient-focused because, according
to the report, patients are considered to be key
team members in the collaborative efforts
required to prevent diagnostic error.
Quickly establishing a correct diagnosis is
critical to the provision of safe and effective
patient care. The problem of diagnostic error
tends to be underappreciated, for several
reasons. Data on diagnostic error are sparse,
few reliable measures exist, and often the error
is identified only in retrospect. The best
estimates indicate that nearly all Americans will
likely experience a meaningful diagnostic error
in their lifetimes. A poll commissioned by the
National Patient Safety Foundation in 1997
found that approximately one in six of those
surveyed had experience with diagnostic error,
either personally or through a close friend or
relative.
On average, 10% of postmortem exams were
associated with diagnostic errors that might
have affected patient outcomes. The report
authors maintained thatreducing diagnostic
error should be a key component of quality
improvement efforts by healthcare
organizations.
Similar to the 2000 IOM report, this report
called for objective, nonpunitive efforts to
understand error and to improve systems and
processes accordingly. This includes learning
from both errors and near misses on one end of
the spectrum and from exemplary accurate and
timely diagnoses on the other end. The report
authors viewed the diagnostic process as a
collaborative activity, often between numerous
professionals and professional groups.
Therefore, improving diagnosis often requires
collaborative efforts between professionals to
understand error and improve performance.
The report authors made eight specific
recommendations forimprovement in the
diagnostic processes:
1. Facilitate more effective teamwork
among healthcare professionals,
patients, and theirfamilies. Radiologists
and pathologists are an integral part of
the diagnostic team.
2. Enhance healthcare professional
education and training in the diagnostic
process.
3. Ensure that health information
technologies support patients and
healthcare professionals.
4. Develop and deploy organizational
approaches to identify, learn from, and
reduce diagnostic errors and near
misses in clinical practice.
5. Establish a work system and culture that
supports the diagnostic process and
improvements in performance. This
may include redesigning payment
structures since fee for service (FFS)
payments lack incentives to coordinate
care among team members, such as
communication among treating
clinicians, pathologists, and radiologists
about diagnostic test ordering,
interpretation, and subsequent decision
making.
6. Develop a reporting environment and
medical liability system that facilitates
improvement.
7. Design a payment and care delivery
environment that supports the
diagnostic process. Specifically,
oversight bodies should require that
healthcare organizations have programs
in place to monitor the diagnostic
process and identify, learn from, and
reduce diagnostic errors and near
misses in a timely fashion.
8. Provide dedicated funding for research
on the diagnostic process and diagnostic
errors.
With respect to radiology, the 2015 IOM report
identified failures in communication as being a
significant contributor to diagnostic error. The
report authors made severalrecommendations
for IT professionals and organizational leaders
to improve communication, including the
following:
• Standardize communication policies
and definitions across networked
organizations
• Ensure clear identification of the
patient’s care team to facilitate contact
by the radiology team
• Implement effective results
management and tracking processes
• Develop shared quality and reporting
metrics


2.2.3 Human Factors
Background
An obstetric nurse connects a bag of pain
medication intended for an epidural catheter to
the mother’s intravenous (IV) line, resulting in
a fatal cardiac arrest. Newborns in a neonatal
intensive care unit are given full-dose heparin
instead of low-dose flushes, leading to three
deaths from intracranial bleeding. An elderly
man experiences cardiac arrest while
hospitalized, but when the code blue team
arrives, the team is unable to administer a
potentially life-saving shock because the
defibrillator pads cannot be connected to the
defibrillator itself.
Busy healthcare workers rely on equipment to
carry out life-saving interventions with the
underlying assumption that technology will
improve outcomes.
But as these examples illustrate, the interaction
between workers, equipment, and the
environment can actually increase the risk of
consequential errors. Each of these safety
hazards ultimately was attributed to a relatively
simple, yet overlooked, problem with system
design.
The bag of epidural anesthetic was similar in
size and shape to IV medication bags, and,
crucially, the same catheter could access both
types of bags. Full-dose and prophylactic-dose
heparin vials appeared virtually identical, and
both concentrations were routinely stocked in
automated dispensers at the point of care.
Multiple brands of defibrillators exist that differ
in physical appearance as well as functionality;
a typical hospital may have many different
models scattered around the building,
sometimes even on the same unit.
Human Factors Engineering
Human factors engineering as a discipline
attempts to identify and address such problems
in a systematic way. It takes into account
human strengths and limitations in the design
of interactive systems that involve people,
equipment, technology, and work
environments to ensure safety, effectiveness,
and ease of use. A human factors engineer
examines a particular activity in terms of its
component tasks and then assesses the human
physical, mental and skill demands in the
context of team dynamics, work environment
(e.g., adequate lighting, limited noise, or other
distractions), and device design required to
optimally perform a task.
In essence, human factors engineering focuses
on how systems work in actual practice, with
real—and fallible—human beings at the
controls. It attempts to design systems that
optimize safety and minimize the risk of error
in complex environments.
Human factors engineering has long been used
to improve safety in many industries, including
aviation and nuclear power. Its application to
healthcare is relatively recent; pioneering
studies of human factors in anesthesia were
integral to the redesign of anesthesia
equipment, significantly reducing the risk of
injury or death in the operating room.
Standardization
Human factors engineering asserts that
equipment and processes should be
standardized whenever possible to increase
reliability, improve information flow, and
minimize cross-training needs. Standardizing
equipment across clinical settings is one basic
example, but standardized processes are
increasingly recognized as a requirement for
safety. The use of checklists as a means of
ensuring that safety steps are performed, and
performed in the correct order, has its roots in
human factors engineering principles.
Establishing an agreed- upon, standardized
approach for the basic elements of a procedure
allows team members to identify when
unintended variances from that approach occur
(which may represent errors) and frees the team
members to better focus on the unique aspects
of the case.
Communication
Effective communication is a critical aspect of
quality and safety in any complex environment.
Communication can be defined as the
meaningful exchange of information between
individuals or groups of individuals; it is often
bidirectional or multidirectional and is
successful when it results in shared
understanding of meaning. Communication
consists of two major parts: 1) conveyance—
transmission of information from a sender to a
receiver, and 2) convergence—verification,
discussion, and clarification until both parties
recognize that they mutually agree (or fail to
agree) on the meaning of the information.
Convergence activities are especially critical
when information is ambiguous or when the
negative impact of a miscommunication would
be severe.
High Reliability Organization (HRO)
In modern medicine, care delivery is frequently
performed in a high complexity setting. A socalled “high reliability organization (HRO)” is
an organization that, despite operating in a
high-stress, high-risk, complex environment,
continually manages its environment
mindfully, adopting a constant state of
vigilance that results in the fewest number of
errors.
Many healthcare organizations are attempting
to adopt high-reliability behaviors and
organizational strategies to reduce medical
errors for their patients.
According to the authors of the concept, HROs
maintain resilience through stressful situations
by both anticipating unexpected events and
containing their impact when they occur.
Anticipation has three elements: preoccupation
with failure, reluctance to simplify, and sensitivity
to operations. Containment has two elements:
commitment to resilience and deferenceto expertise.
These can be described as follows:
Anticipation
1. Preoccupation with failure. Members of
the organization recognize that even
minor lapses can have severe
consequences and tend to be
deliberately watchful for clues that
indicate trouble. The organizations have
processes in place to enable individuals,
teams, and systems to quickly detect
and respond to potential threats before
they result in harm.
2. Reluctance to simplify. When problems
arise, rather than accept simple
explanations, individuals are expected
to dig deeper to understand the source
of the problem.
3. Sensitivity to operations. Members of
the organization—especially the
leaders—continuously understand the
messy reality of the details of what is
actually happening in the place of work
rather than what is supposed to be
happening and respond accordingly.
Containment
1. Commitment to resilience. It is
assumed that unexpected trouble is both
ubiquitous and unpredictable. HROs
recognize that they can never fully
anticipate each unexpected event, so
they empowerindividuals to adjust and
innovate as necessary and then seek to
learn from those situations.
2. Deference to expertise. No one
individual ever knows everything about
any situation. People with greater
authority often have less useful
knowledge about a situation than those
with lesser authority. HROs overcome
the dangers of hierarchy by enabling
leaders to defer to the relevant expertise,
regardless of its source, while
preserving the organizational structure.
2.2.4 Human Error
People are prone to error, but not all errors are
identical.
A commonly used human error classification
scheme is the “skill-rule-knowledge” (SRK)
model. This model refers to the cognitive mode
in which the individual is operating when he or
she commits an error. Actions that are largely
performed automatically, requiring little
conscious attention, are considered skill-based
actions, such as tying one’s shoes or driving on
the open freeway. Actions that require an
intermediate level of attention are considered
rules-based actions, such as deciding which
clothes to wear or when to proceed at a fourway stop. Actions that require a high level of
concentration, usually in the setting of
situations that are new to the individual, are
knowledge-based actions, such as playing a
sport for the first time or driving in poor
visibility conditions in an unfamiliar city.
Appropriate strategies for ensuring safety in
the face of human error depend on the type of
error committed. Skill-based errors tend to be
amenable to behavior- shaping constraints that
make it hard to perform the wrong action (i.e.,
forcing functions, such as a microwave that
cannot be operated with the door open) and
enablers that make it easy to perform the right
action (i.e., affordances, such as installing a
door handle for pulling and a plate for
pushing). Rules- and knowledge-based errors
tend to be amenable to increased supervision,
additional training and coaching, deliberate
practice, and intelligent decision support.
Note that additional training is generally less
effective for skill-based errors, and behavior
shaping constraints are less effective for rulesor knowledge-based mistakes. For example, a
radiologist who accidentally dictates “100 mg”
instead of “100 μg” is unlikely to benefit from
an educational course on units of measure in
the metric system. Conversely, a simple clinical
decision-support rule that forces a physician to
order ultrasonography when he or she thinks
that magnetic resonance imaging is warranted
is more likely to be ignored and thus less likely
to be successful than education and consensusbuilding efforts. Thus, in learning from an
error, it is important to determine the cognitive
mode in which the individual was operating at
the time

2.2.5 Culture of Safety
Background
The concept of safety culture originated in
studies of high reliability organizations. High
reliability organizations maintain a
commitment to safety at all levels, from
frontline providers to managers and executives.
According to the Agency for Healthcare
Research and Quality (AHRQ), this
commitment establishes a “culture of safety”
that encompasses the following key features:
• Acknowledgment of the high-risk
nature of an organization’s activities
and the determination to achieve
consistently safe operations
• A blame-free environment where
individuals are able to report errors or
near misses without fear ofreprimand
or punishment
• Encouragement of collaboration across
ranks and disciplines to seek solutions
to patient safety problems
• Organizational commitment of
resources to address safety concerns
Studies have documented considerable
variation in perceptions of safety culture across
organizations and job descriptions. Historically,
nurses have often complained of the lack of a
blame-free environment and providers at all
levels have noted problems with organizational
commitment to establishing a culture of safety.
The underlying reasons for the underdeveloped
healthcare safety culture include poor
teamwork and communication, a “culture of
low expectations,” and the presence of steep
authority gradients.
Authority Gradient
In an organization with steep authority
gradients, especially where there is fear of
punishment for errors, quality and safety
problems are rarely reported to senior
leadership. In this way, such authority
gradients not only undermine the safety
culture, but increase the difficulty of accurately
measuring error rates.
Measuring and Achieving a Culture of Safety
Perceptions by the staff of poor safety culture
have been linked to increased error rates. Safety
culture can be measured by surveys of
providers at all levels. Available validated
surveys include the AHRQ’s Patient Safety
Culture Surveys and the Safety Attitudes
Questionnaire.
Just Culture
The traditional culture of individual blame,
which still dominates some healthcare
organizations, impairs the advancement of a
safety culture. However, while blame is
generally an undesirable approach to safety,
individuals need to be held accountable for
their actions to a certain degree. In an effort to
reconcile the need for reducing a focus on
blame and maintaining individual
accountability, the concept of “just culture” was
proposed by David Marx. The just culture
model distinguishes between human error(e.g.,
slips), at-risk behavior (e.g., taking shortcuts),
and reckless behavior (e.g., flaunting firmly
established safety rules). In this model, the
response to an error or near miss is predicated
on the type of behavior associated with the
error, not the outcome or severity of the event.
For example, reckless behavior, in which firmly
established safety norms are willfully ignored,
such as a physician who refuses to perform a
time out before surgery, may merit firm—
possibly punitive—action, even if no patients
were harmed. In contrast, a person who makes
an innocent human error, even if this error
resulted in significant patient harm, would be
consoled since human errors are considered to
be inevitable and not necessarily the result of
negligence. In the middle ground, those
persons who engage in at-risk behavior— e.g.,
workarounds of convenience, such as failing to
communicate criticalresults, that could subvert
established safety precautions—probably
underestimate the risks of their actions. These
persons are counseled or coached in the Just
Culture Model (Table 2.1).
A safety coach or champion is a person in the
organization who takes ownership of the
processes and fosters the creation and
maintenance of the safety culture, including
oversight of safety-reporting systems whereby
safety incidents and near-miss events are
reported and archived. In a safety-reporting
system, the primary focus is on the patient, the
event, and the processes and systems to
identify opportunities for sustainable
improvement. The individual who made the
error should not be the focus of the
investigation, as long as the individual was not
acting recklessly. In other words, the reporting
system should not be used as a means of
instigating punitive action.
The term “second victim” has been coined for a
healthcare worker who is traumatized by an
error or adverse patient event in which they
were involved.
These individuals often feel an intense sense of
guilt, sorrow, and anxiety, and may even
exhibit signs similar to post-traumatic stress
disorder. Many hospitals have begun to
develop internal programs to identify, console,
and advocate on behalf of such individuals.

The Just Culture Model outlines three manageable behaviors: Human Error, At-risk Behavior, and Reckless Behavior.

Human Error is defined as a product of our current system design and our behavioral choices. Management strategies include modifying available choices, changing processes or workflows, improving training programs, or redesigning the system or facility. The recommended approach to the individual is to console.

At-risk Behavior is defined as a choice where the risk is believed to be insignificant or justified. Management strategies include counseling the individual, better incentivizing correct behavior, and modifying processes, training, or other factors as needed. The recommended approach to the individual is to coach.

Reckless Behavior is defined as a conscious disregard for a substantial and unjustifiable risk. Management strategies include remediating or removing the individual from the environment and taking punitive action as warranted. The recommended approach to the individual is to punish or sanction.